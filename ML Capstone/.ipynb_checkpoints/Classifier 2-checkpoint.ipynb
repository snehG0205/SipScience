{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/snehgajiwala/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MenuClassifier:\n",
    "    \n",
    "    vectorizer = CountVectorizer(min_df=1)\n",
    "    tfidfconverter = TfidfTransformer()\n",
    "    \n",
    "    \n",
    "    def getModel(self):\n",
    "    \n",
    "        data = pd.read_csv(\"Menu.csv\")\n",
    "\n",
    "        X = data.drop('Category', axis=1)\n",
    "        y = data['Category']\n",
    "\n",
    "        documents_train = self.getWords(X['Item Name'])\n",
    "\n",
    "        X = vectorizer.fit_transform(documents_train).toarray()\n",
    "        X = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=10, random_state=None)\n",
    "        model.fit(X_train, y_train) \n",
    "        \n",
    "        return (model)\n",
    "    \n",
    "    def getWords(self, X):\n",
    "        documents = []\n",
    "\n",
    "        stemmer = WordNetLemmatizer()\n",
    "\n",
    "        for sen in range(0, len(X)):\n",
    "            # Remove all the special characters\n",
    "            document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "            # remove all single characters\n",
    "            document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "            # Remove single characters from the start\n",
    "            document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "            # Substituting multiple spaces with single space\n",
    "            document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "            # Removing prefixed 'b'\n",
    "            document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "            # Converting to Lowercase\n",
    "            document = document.lower()\n",
    "\n",
    "            # Lemmatization\n",
    "            document = document.split()\n",
    "\n",
    "            document = [stemmer.lemmatize(word) for word in document]\n",
    "            document = ' '.join(document)\n",
    "\n",
    "            documents.append(document)\n",
    "\n",
    "        return(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = MenuClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = obj.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ['Lite Beer','Chicken Pasta','Sour Whiskey','Bloody Mary', 'Cobb Salad', 'Meatball Spaghetti',\n",
    "             'Screwdriver', 'Beef Rice', 'Spl Taco', 'Long Island Ice Tea', 'Miller Lite', \n",
    "             'Cheesecake','Bousquet Rose']\n",
    "y_real = ['Drink', 'Food', 'Drink', 'Drink','Food','Food','Drink','Food','Food','Drink','Drink',\n",
    "          'Food','Drink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_test = obj.getWords(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MenuClassifier' object has no attribute 'vectorizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-318-ec4017729562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfidfconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MenuClassifier' object has no attribute 'vectorizer'"
     ]
    }
   ],
   "source": [
    "X_new = obj.vectorizer.transform(documents_test).toarray()\n",
    "X_new = obj.tfidfconverter.transform(X_new).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
