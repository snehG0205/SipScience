{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json  \n",
    "from pandas.io.json import json_normalize  \n",
    "import psycopg2\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genereating the timestamps\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the location IDs (just 1-Fred's for now)\n",
    "link = 'https://api.omnivore.io/1.0/locations/'\n",
    "\n",
    "headers = {\n",
    "    'Api-Key': '3a01cc5779ef4e3784658607fc188719',\n",
    "}\n",
    "\n",
    "response = requests.get(link, headers=headers)\n",
    "s = response.text\n",
    "j = json.loads(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of location IDs\n",
    "df = json_normalize(j['_embedded']['locations'])\n",
    "location_ids = df['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving tickets for location IDs\n",
    "link_new = link+location_ids[0]+\"/tickets/\"\n",
    "\n",
    "headers = {\n",
    "    'Api-Key': '3a01cc5779ef4e3784658607fc188719',\n",
    "}\n",
    "\n",
    "response = requests.get(link_new, headers=headers)\n",
    "s = response.text\n",
    "j = json.loads(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the raw tickets to a json\n",
    "fname = \"data_\"+timestr+\".json\"\n",
    "with open(fname, 'w') as f:\n",
    "        json.dump(j, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the json to a dataframe (table)\n",
    "df = json_normalize(j['_embedded']['tickets'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving items and categories from the ticket\n",
    "item_name = []\n",
    "item_category = []\n",
    "for x in df['_embedded.items']:\n",
    "    x = json_normalize(x)\n",
    "    if x.empty:\n",
    "        item_name.append(\"None\")\n",
    "        item_category.append(\"None\")\n",
    "    else:\n",
    "        item_all = x['_embedded.menu_item.name']\n",
    "        cat_j = x['_embedded.menu_item._embedded.menu_categories']\n",
    "        items = ', '.join(item_all.tolist())\n",
    "        cat_all = []\n",
    "        for q in cat_j:\n",
    "            p = json_normalize(q)\n",
    "            c = p['name']\n",
    "            c = set(c)\n",
    "            l = ', '.join(list(c))\n",
    "            cat_all.append(l)\n",
    "            cat_all = list(set(cat_all))\n",
    "        categories = ', '.join((cat_all))\n",
    "\n",
    "        item_name.append(items)\n",
    "        item_category.append(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a table of relevant features\n",
    "new_df = pd.DataFrame()\n",
    "new_df['Ticket_ID'] = df['id']\n",
    "new_df['Total'] = df['totals.total']/100\n",
    "new_df['Subtotal'] = df['totals.sub_total']/100\n",
    "new_df['Tax'] = df['totals.tax']/100\n",
    "new_df['Tips'] = df['totals.tips']/100\n",
    "new_df['Opened At'] = df['opened_at']\n",
    "new_df['Closed At'] = df['closed_at']\n",
    "new_df['Order Type'] = df['_embedded.order_type.name']\n",
    "new_df['Item Name'] = item_name\n",
    "new_df['Category Name'] = item_category\n",
    "new_df['Closed At'] = new_df['Closed At'].fillna(\"None\")\n",
    "# new_df.set_index(\"Ticket_ID\", inplace = True) \n",
    "\n",
    "opened_unix = new_df['Opened At'].tolist()\n",
    "closed_unix = new_df['Closed At'].tolist()\n",
    "opened_ts = []\n",
    "closed_ts = []\n",
    "for i in opened_unix:\n",
    "    ts = int(i)\n",
    "    opened_ts.append(datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "for j in closed_unix:\n",
    "    ts = int(i)\n",
    "    closed_ts.append(datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "opened_ts,closed_ts\n",
    "new_df['Opened At'] = opened_ts\n",
    "new_df['Closed At'] = closed_ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to POSTGRE\n",
    "hostname = '127.0.0.1'\n",
    "username = 'postgres'\n",
    "password = 'S8Huu6xxCBBZ3ep'\n",
    "database = 'postgres'\n",
    "\n",
    "connection = psycopg2.connect( host=hostname, user=username, password=password, dbname=database )\n",
    "cursor = connection.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for tickets already in the postgre\n",
    "cursor.execute( \"SELECT ticketid FROM OmnivoreData\" )\n",
    "existing_tickets = []\n",
    "for tId in cursor.fetchall() :\n",
    "    existing_tickets.append(str(tId[0]))\n",
    "    \n",
    "new_df=new_df[~new_df['Ticket_ID'].isin(existing_tickets)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200821-150738 => Records inserted\n"
     ]
    }
   ],
   "source": [
    "# Writing the new tickets to POstgre\n",
    "\n",
    "if not new_df.empty:\n",
    "    for Ticket_ID, df in new_df.groupby('Ticket_ID'):\n",
    "        ticketId = str(df['Ticket_ID'].values[0])\n",
    "        total = str(df['Total'].values[0])\n",
    "        subtotal = str(df['Subtotal'].values[0])\n",
    "        tax = str(df['Tax'].values[0])\n",
    "        tips = str(df['Tips'].values[0])\n",
    "        openedAt = str(df['Opened At'].values[0])\n",
    "        closedAt = str(df['Closed At'].values[0])\n",
    "        orderType = str(df['Order Type'].values[0])\n",
    "        itemName = str(df['Item Name'].values[0])\n",
    "        catName = str(df['Category Name'].values[0])\n",
    "\n",
    "\n",
    "\n",
    "        postgres_insert_query =  \"INSERT INTO OmnivoreData VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\"\n",
    "        record_to_insert = (ticketId,total,subtotal,tax,openedAt,closedAt,orderType,itemName,catName,tips)\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "    \n",
    "    print(str(timestr)+\" => Records inserted\")\n",
    "\n",
    "else:\n",
    "    print(str(timestr)+\" => Database is up to date\")\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the items and categories for normalization\n",
    "s = response.text\n",
    "j = json.loads(s)\n",
    "df = json_normalize(j['_embedded']['tickets']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = pd.DataFrame(columns = ['Ticket_Id', 'Opened_At','Closed_At','Item_Name', 'Categories', 'Price'])\n",
    "\n",
    "for Ticket_Id, tickets in df.groupby('id'):\n",
    "\n",
    "    for x in tickets['_embedded.items']:\n",
    "        x = json_normalize(x)\n",
    "        if not x.empty:\n",
    "            i_list = x.name.tolist()\n",
    "            i_pricelist = x.price.tolist()\n",
    "            category_list = []\n",
    "            for y in x['_embedded.menu_item._embedded.menu_categories']:\n",
    "                y = json_normalize(y)\n",
    "                z = y.name.tolist()\n",
    "#                 print(z)\n",
    "                for i in range(len(z)):\n",
    "#                     print(i)\n",
    "                    z[i] = z[i].strip()\n",
    "                z = list(set(z))\n",
    "                category_list.append(z)\n",
    "#             print(i_list)\n",
    "#             print(category_list)\n",
    "\n",
    "            opened_unix = tickets['opened_at'].tolist()\n",
    "            closed_unix = tickets['closed_at'].tolist()\n",
    "            opened_ts = []\n",
    "            closed_ts = []\n",
    "            for i in opened_unix:\n",
    "                ts = int(i)\n",
    "                opened_ts.append(datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "            for j in closed_unix:\n",
    "                ts = int(i)\n",
    "                closed_ts.append(datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            \n",
    "            for i in range(len(category_list)):\n",
    "                cat = ', '.join(category_list[i])\n",
    "                item_data.loc[len(item_data)] = [Ticket_Id, opened_ts[0], closed_ts[0], i_list[i], cat, i_pricelist[i]/100]\n",
    "#     print(\"*********\")\n",
    " \n",
    "# item_data         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing normalized item data\n",
    "\n",
    "cursor.execute( \"SELECT ticketid FROM OmnivoreItemData\" )\n",
    "existing_tickets = []\n",
    "for tId in cursor.fetchall() :\n",
    "    existing_tickets.append(str(tId[0]))\n",
    "    \n",
    "item_data = item_data[~item_data['Ticket_Id'].isin(existing_tickets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200821-150738 => Records inserted\n"
     ]
    }
   ],
   "source": [
    "if not item_data.empty:\n",
    "    for i,row in item_data.iterrows():\n",
    "        postgres_insert_query =  \"INSERT INTO OmnivoreItemData VALUES (%s,%s,%s,%s,%s,%s);\"\n",
    "        record_to_insert = (str(row['Ticket_Id']),str(row['Opened_At']),str(row['Closed_At']),str(row['Item_Name']),str(row['Categories']),str(row['Price']))\n",
    "#         print(record_to_insert)\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "\n",
    "    \n",
    "    print(str(timestr)+\" => Records inserted\")\n",
    "\n",
    "else:\n",
    "    print(str(timestr)+\" => Database is up to date\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing normalized category data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_data = pd.DataFrame(columns = ['Ticket_Id', 'Opened_At','Closed_At','Item_Name', 'Categories', 'Price'])\n",
    "for i,row in item_data.iterrows():\n",
    "    cat_list = row['Categories'].split(\", \")\n",
    "    for j in cat_list:\n",
    "        category_data.loc[len(category_data)] = [row['Ticket_Id'], row['Opened_At'],row['Closed_At'],row['Item_Name'], j, row['Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cursor.execute( \"SELECT ticketid FROM OmnivoreCategoryData\" )\n",
    "existing_tickets = []\n",
    "for tId in cursor.fetchall() :\n",
    "    existing_tickets.append(str(tId[0]))\n",
    "    \n",
    "category_data = category_data[~category_data['Ticket_Id'].isin(existing_tickets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200821-150738 => Records inserted\n"
     ]
    }
   ],
   "source": [
    "if not category_data.empty:\n",
    "    for i,row in category_data.iterrows():\n",
    "        postgres_insert_query =  \"INSERT INTO OmnivoreCategoryData VALUES (%s,%s,%s,%s,%s,%s);\"\n",
    "        record_to_insert = (str(row['Ticket_Id']),str(row['Opened_At']),str(row['Closed_At']),str(row['Item_Name']),str(row['Categories']),str(row['Price']))\n",
    "#         print(record_to_insert)\n",
    "        cursor.execute(postgres_insert_query, record_to_insert)\n",
    "        connection.commit()\n",
    "    print(str(timestr)+\" => Records inserted\")\n",
    "\n",
    "else:\n",
    "    print(str(timestr)+\" => Database is up to date\")\n",
    "    \n",
    "    \n",
    "    \n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
